{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDataFrame = pd.read_csv('./data/trainLevel1Preds.csv')\n",
    "#trainLabels = trainDataFrame['TARGET']\n",
    "#trainFeatures = trainDataFrame.drop(['TARGET'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 189)\n"
     ]
    }
   ],
   "source": [
    "print trainDataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRandomSubSet(ratio=.5):\n",
    "    n_samples = int(trainDataFrame.shape[0]*ratio)\n",
    "    # shuffle\n",
    "    trn_shuffled = trainDataFrame.reindex(np.random.permutation(trainDataFrame.index))\n",
    "\n",
    "    return trn_shuffled[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 'xgb_13' to ensemble w contribution score 0.356300\n",
      "added 'xgb_11' to ensemble w contribution score 0.001679\n",
      "added 'xgb_19' to ensemble w contribution score 0.000753\n",
      "added 'xgb_5' to ensemble w contribution score 0.000406\n",
      "added 'xgb_18' to ensemble w contribution score 0.000216\n",
      "added 'xgb_9' to ensemble w contribution score 0.000323\n",
      "added 'xgb_10' to ensemble w contribution score 0.000174\n",
      "added 'xgb_6' to ensemble w contribution score 0.000157\n",
      "added 'rfc_14' to ensemble w contribution score 0.000200\n",
      "added 'xgb_17' to ensemble w contribution score 0.000080\n",
      "added 'xgb_11' to ensemble w contribution score 0.000088\n",
      "added 'xgb_17' to ensemble w contribution score 0.000038\n",
      "added 'xgb_0' to ensemble w contribution score 0.000069\n",
      "added 'xgb_14' to ensemble w contribution score 0.000023\n",
      "added 'xgb_3' to ensemble w contribution score 0.000107\n",
      "added 'xgb_11' to ensemble w contribution score 0.000078\n",
      "added 'xgb_10' to ensemble w contribution score 0.000077\n",
      "added 'rfc_10' to ensemble w contribution score 0.000098\n",
      "added 'xgb_10' to ensemble w contribution score 0.000050\n",
      "added 'xgb_5' to ensemble w contribution score 0.000030\n",
      "added 'xgb_9' to ensemble w contribution score 0.000050\n",
      "added 'xgb_13' to ensemble w contribution score 0.000036\n",
      "added 'xgb_17' to ensemble w contribution score 0.000016\n",
      "added 'xgb_18' to ensemble w contribution score 0.000041\n",
      "added 'xgb_19' to ensemble w contribution score 0.000030\n",
      "added 'xgb_9' to ensemble w contribution score 0.000035\n",
      "added 'xgb_15' to ensemble w contribution score 0.000017\n",
      "added 'xgb_14' to ensemble w contribution score 0.000041\n",
      "added 'rfc_13' to ensemble w contribution score 0.000013\n",
      "added 'xgb_3' to ensemble w contribution score 0.000046\n",
      "added 'xgb_0' to ensemble w contribution score 0.000049\n",
      "added 'xgb_13' to ensemble w contribution score 0.000042\n",
      "added 'xgb_16' to ensemble w contribution score 0.000014\n",
      "added 'xgb_6' to ensemble w contribution score 0.000036\n",
      "added 'xgb_10' to ensemble w contribution score 0.000015\n",
      "added 'xgb_11' to ensemble w contribution score 0.000035\n",
      "added 'xgb_18' to ensemble w contribution score 0.000015\n",
      "added 'xgb_6' to ensemble w contribution score 0.000015\n",
      "added 'xgb_9' to ensemble w contribution score 0.000016\n",
      "added 'rfc_10' to ensemble w contribution score 0.000012\n",
      "added 'xgb_5' to ensemble w contribution score 0.000036\n",
      "added 'xgb_19' to ensemble w contribution score 0.000012\n",
      "added 'xgb_11' to ensemble w contribution score 0.000024\n",
      "added 'xgb_9' to ensemble w contribution score 0.000021\n",
      "added 'rfc_18' to ensemble w contribution score 0.000029\n",
      "added 'xgb_3' to ensemble w contribution score 0.000013\n",
      "added 'xgb_5' to ensemble w contribution score 0.000008\n",
      "added 'xgb_6' to ensemble w contribution score 0.000008\n",
      "added 'xgb_9' to ensemble w contribution score 0.000015\n",
      "added 'xgb_11' to ensemble w contribution score 0.000015\n",
      "-----------------------\n",
      "Ensemble: ['xgb_13', 'xgb_11', 'xgb_19', 'xgb_5', 'xgb_18', 'xgb_9', 'xgb_10', 'xgb_6', 'rfc_14', 'xgb_17', 'xgb_11', 'xgb_17', 'xgb_0', 'xgb_14', 'xgb_3', 'xgb_11', 'xgb_10', 'rfc_10', 'xgb_10', 'xgb_5', 'xgb_9', 'xgb_13', 'xgb_17', 'xgb_18', 'xgb_19', 'xgb_9', 'xgb_15', 'xgb_14', 'rfc_13', 'xgb_3', 'xgb_0', 'xgb_13', 'xgb_16', 'xgb_6', 'xgb_10', 'xgb_11', 'xgb_18', 'xgb_6', 'xgb_9', 'rfc_10', 'xgb_5', 'xgb_19', 'xgb_11', 'xgb_9', 'rfc_18', 'xgb_3', 'xgb_5', 'xgb_6', 'xgb_9', 'xgb_11']\n",
      "Score: 0.857926\n",
      "Total Time (mins): 6.9\n"
     ]
    }
   ],
   "source": [
    "# cross validated performance\n",
    "n_folds = 5\n",
    "n_max_ensemble_models = 50\n",
    "with_replacement = True\n",
    "ensemble = []\n",
    "target = 'TARGET'\n",
    "models = [x for x in trainDataFrame.columns if x not in [target]]\n",
    "start = time.time()\n",
    "for m in range(n_max_ensemble_models):\n",
    "    models_candidates = [x for x in models if x not in ensemble] if not with_replacement else models\n",
    "    models_candidates_scores = pd.DataFrame(index=range(n_folds), columns=models_candidates, \n",
    "                                            data=np.zeros([n_folds, len(models_candidates)]))\n",
    "    for i in range(n_folds):\n",
    "        trn = getRandomSubSet(ratio=.2)\n",
    "        ensemble_preds = trn[ensemble].mean(axis=1) if ensemble else np.zeros(trn.shape[0])\n",
    "        ensemble_score = roc_auc_score(trn[target], ensemble_preds)\n",
    "        for model in models_candidates:\n",
    "            model_preds = trn[ensemble+[model]].mean(axis=1)\n",
    "            models_candidates_scores[model].ix[i] = roc_auc_score(trn[target], model_preds) - ensemble_score\n",
    "            #print \"'%s' Contribution Score: %.4f\" % (model, (roc_auc_score(trn[target], model_preds) - ensemble_score)) \n",
    "    model_score_means = models_candidates_scores.mean()\n",
    "    model_max_contribution = model_score_means.idxmax()\n",
    "    if model_score_means[model_max_contribution] <= 0:\n",
    "        print \"Best model '%s' has a contribution of %.4f, thus skipped.\" % (\n",
    "            model_max_contribution, model_score_means[model_max_contribution])\n",
    "        continue\n",
    "    \n",
    "    ensemble.append(model_max_contribution)\n",
    "    print \"added '%s' to ensemble w contribution score %.6f\" % (model_max_contribution\n",
    "                                                                , model_score_means[model_max_contribution])\n",
    "\n",
    "trn = getRandomSubSet(ratio=1.)\n",
    "ensemble_preds = trn[ensemble].mean(axis=1) if ensemble else np.zeros(trn.shape[0])\n",
    "ensemble_score = roc_auc_score(trn[target], ensemble_preds)\n",
    "\n",
    "print \"-----------------------\"\n",
    "print \"Ensemble: %s\" % ensemble\n",
    "print \"Score: %.6f\" % ensemble_score\n",
    "print \"Total Time (mins): %.1f\" % ((time.time()-start)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbc_0</th>\n",
       "      <th>gbc_1</th>\n",
       "      <th>gbc_2</th>\n",
       "      <th>gbc_3</th>\n",
       "      <th>gbc_4</th>\n",
       "      <th>gbc_5</th>\n",
       "      <th>gbc_6</th>\n",
       "      <th>gbc_7</th>\n",
       "      <th>gbc_8</th>\n",
       "      <th>gbc_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fnn_10</th>\n",
       "      <th>fnn_11</th>\n",
       "      <th>fnn_12</th>\n",
       "      <th>fnn_13</th>\n",
       "      <th>fnn_14</th>\n",
       "      <th>fnn_15</th>\n",
       "      <th>fnn_16</th>\n",
       "      <th>fnn_17</th>\n",
       "      <th>fnn_18</th>\n",
       "      <th>fnn_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000489</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>-0.000586</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>-0.000643</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001393</td>\n",
       "      <td>-0.001261</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>-0.001248</td>\n",
       "      <td>-0.001218</td>\n",
       "      <td>-0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000278</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>-0.000344</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000799</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000743</td>\n",
       "      <td>-0.000740</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>-0.000772</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-0.000723</td>\n",
       "      <td>-0.000798</td>\n",
       "      <td>-0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000621</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.000883</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.000906</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>-0.001047</td>\n",
       "      <td>-0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>-0.000384</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>-0.001157</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>-0.000983</td>\n",
       "      <td>-0.000969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000587</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.001229</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>-0.001220</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-0.001231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gbc_0     gbc_1     gbc_2     gbc_3     gbc_4     gbc_5     gbc_6  \\\n",
       "0 -0.000489 -0.000553 -0.000586 -0.000727 -0.000643 -0.000536 -0.000765   \n",
       "1 -0.000278 -0.000183 -0.000344 -0.000467 -0.000293 -0.000369 -0.000323   \n",
       "2 -0.000621 -0.000438 -0.000540 -0.000374 -0.000513 -0.000217 -0.000331   \n",
       "3 -0.000623 -0.000515 -0.000763 -0.000578 -0.000667 -0.000384 -0.000696   \n",
       "4 -0.000587 -0.000621 -0.000649 -0.000622 -0.000678 -0.000604 -0.000577   \n",
       "\n",
       "      gbc_7     gbc_8     gbc_9    ...       fnn_10    fnn_11    fnn_12  \\\n",
       "0 -0.000698 -0.000604 -0.000343    ...    -0.001393 -0.001261 -0.000936   \n",
       "1 -0.000314 -0.000408 -0.000294    ...    -0.000799 -0.000797 -0.000743   \n",
       "2 -0.000409 -0.000490 -0.000228    ...    -0.001092 -0.000884 -0.000883   \n",
       "3 -0.000687 -0.000512 -0.000463    ...    -0.000960 -0.000917 -0.000861   \n",
       "4 -0.000720 -0.000706 -0.000181    ...    -0.001236 -0.001203 -0.000930   \n",
       "\n",
       "     fnn_13    fnn_14    fnn_15    fnn_16    fnn_17    fnn_18    fnn_19  \n",
       "0 -0.001168 -0.001065 -0.001098 -0.001302 -0.001248 -0.001218 -0.001203  \n",
       "1 -0.000740 -0.000785 -0.000772 -0.000745 -0.000723 -0.000798 -0.000869  \n",
       "2 -0.001005 -0.000906 -0.000953 -0.000996 -0.000941 -0.001047 -0.001066  \n",
       "3 -0.001044 -0.000915 -0.000963 -0.001157 -0.000917 -0.000983 -0.000969  \n",
       "4 -0.001229 -0.001089 -0.001105 -0.001168 -0.001220 -0.001366 -0.001231  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_candidates_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38000, 1)\n",
      "(38000,)\n",
      "(38020, 1)\n",
      "(38020,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_val.shape\n",
    "print y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2596,  404],\n",
       "       [ 510,  998]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, clf.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train on all data and save feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=7, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(max_features=7)\n",
    "model.fit(trainFeatures, trainLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_imps_for_level1preds_w_gbc_mf7_all_trainset_sorted = sorted(zip(trainFeatures.columns, model.feature_importances_), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rfc_5', 0.022271219436144626),\n",
       " ('xgb_4', 0.020745370418321536),\n",
       " ('rfc_17', 0.017732956220901371),\n",
       " ('xgb_9', 0.017092360257458746),\n",
       " ('xgb_11', 0.016114674394330394),\n",
       " ('svm_16', 0.0160096314446889),\n",
       " ('rfc_2', 0.015823938142816171),\n",
       " ('xgb_17', 0.015756475145877455),\n",
       " ('xgb_12', 0.015720812054844834),\n",
       " ('rfc_18', 0.01550412648583859),\n",
       " ('rfc_13', 0.015199231880057527),\n",
       " ('xgb_8', 0.014816468129873922),\n",
       " ('svm_15', 0.0132701715292295),\n",
       " ('lr_19', 0.013166665953654186),\n",
       " ('fnn_10', 0.012978292938358766),\n",
       " ('rfc_3', 0.012093217772584007),\n",
       " ('gbc_7', 0.011777018041079928),\n",
       " ('gbc_2', 0.011646806421891431),\n",
       " ('svm_12', 0.011437337872007118),\n",
       " ('xgb_10', 0.011201223101746436),\n",
       " ('xgb_14', 0.011070345072233558),\n",
       " ('xgb_2', 0.011054223494070066),\n",
       " ('xgb_5', 0.010904807731260135),\n",
       " ('xgb_6', 0.01078255866133758),\n",
       " ('svm_17', 0.01054030719700017),\n",
       " ('gbc_18', 0.010350142038380193),\n",
       " ('svm_0', 0.010195283386965192),\n",
       " ('svm_9', 0.0099980222730563176),\n",
       " ('svm_5', 0.0094899618469975345),\n",
       " ('etc_9', 0.0093723939477139279),\n",
       " ('etc_2', 0.009113852670214374),\n",
       " ('rfc_16', 0.0091043162295515855),\n",
       " ('fnn_5', 0.0090531313618776206),\n",
       " ('svm_13', 0.0090260615408130213),\n",
       " ('etc_13', 0.0089721489378179302),\n",
       " ('knn_5', 0.008766519698498218),\n",
       " ('xgb_0', 0.0087287300555372611),\n",
       " ('xgb_16', 0.0087186541643411199),\n",
       " ('xgb_18', 0.0086833548384173866),\n",
       " ('xgb_1', 0.0085557583821260202),\n",
       " ('lr_13', 0.0085495442855101581),\n",
       " ('gbc_19', 0.0082969074894841573),\n",
       " ('gbc_1', 0.0081645035162815384),\n",
       " ('rfc_0', 0.0080742850602262984),\n",
       " ('xgb_13', 0.0080203356401092659),\n",
       " ('svm_8', 0.0076812307823960367),\n",
       " ('fnn_12', 0.0074430673732774986),\n",
       " ('gbc_3', 0.007204988117324943),\n",
       " ('gbc_15', 0.007187509273717506),\n",
       " ('fnn_15', 0.0071800168905376037),\n",
       " ('xgb_7', 0.0071768772737197438),\n",
       " ('lr_2', 0.0068705903415508798),\n",
       " ('rfc_4', 0.0067936411667973619),\n",
       " ('rfc_10', 0.0066628758043682981),\n",
       " ('lr_3', 0.0065510932422039184),\n",
       " ('gbc_0', 0.0065311408922835885),\n",
       " ('svm_2', 0.0065235394657380905),\n",
       " ('lr_0', 0.0065220054646211055),\n",
       " ('lr_5', 0.0064921010840775749),\n",
       " ('gbc_4', 0.0063830317323734813),\n",
       " ('etc_15', 0.0062829391749852316),\n",
       " ('rfc_1', 0.0062365005240863237),\n",
       " ('lr_9', 0.0062278290635167073),\n",
       " ('fnn_18', 0.0060983293888495381),\n",
       " ('dtc_4', 0.0060866145120893889),\n",
       " ('knn_0', 0.0060812009782272849),\n",
       " ('gbc_12', 0.0060407469539382674),\n",
       " ('gbc_8', 0.0059016584832263987),\n",
       " ('etc_18', 0.0059013041528291907),\n",
       " ('fnn_8', 0.0058970964731994554),\n",
       " ('rfc_7', 0.0057767509774164956),\n",
       " ('lr_7', 0.005764792620015593),\n",
       " ('xgb_3', 0.0057552531939030491),\n",
       " ('fnn_9', 0.0057113820427430262),\n",
       " ('etc_11', 0.0056946052333920428),\n",
       " ('fnn_19', 0.0056910373801797552),\n",
       " ('svm_11', 0.0056527599554888593),\n",
       " ('lr_4', 0.0055793828985104136),\n",
       " ('gbc_16', 0.0055313722878172359),\n",
       " ('dtc_10', 0.0055223370720803933),\n",
       " ('lr_6', 0.0054767231956874681),\n",
       " ('rfc_6', 0.0053878446539273647),\n",
       " ('gbc_10', 0.005274679730447273),\n",
       " ('gbc_5', 0.0052389538328747702),\n",
       " ('dtc_18', 0.0052129437056615303),\n",
       " ('knn_3', 0.0051190178824316469),\n",
       " ('xgb_15', 0.0051114075702867624),\n",
       " ('fnn_6', 0.0050209648172668438),\n",
       " ('rfc_11', 0.0049832659527756671),\n",
       " ('svm_10', 0.0049470615942935284),\n",
       " ('fnn_11', 0.0049228681003292184),\n",
       " ('rfc_8', 0.0049159888591527494),\n",
       " ('lr_8', 0.0048259924471818084),\n",
       " ('rfc_12', 0.0047233022403595079),\n",
       " ('etc_19', 0.004715358194180023),\n",
       " ('fnn_13', 0.0047148721059761577),\n",
       " ('etc_17', 0.0047005116249037061),\n",
       " ('xgb_19', 0.0046814902743771694),\n",
       " ('bnb_18', 0.0045581611187608603),\n",
       " ('svm_14', 0.0045549286949084274),\n",
       " ('knn_4', 0.0045306955804477007),\n",
       " ('fnn_3', 0.0045031355639127916),\n",
       " ('etc_16', 0.0044055992863211504),\n",
       " ('etc_6', 0.0043738309067035209),\n",
       " ('gbc_9', 0.0043691758494629604),\n",
       " ('etc_10', 0.0043640088145004748),\n",
       " ('rfc_15', 0.0043002495476687644),\n",
       " ('gbc_14', 0.0040763449716839009),\n",
       " ('rfc_9', 0.0038240445665026512),\n",
       " ('etc_12', 0.0037910184484660297),\n",
       " ('etc_1', 0.0037421980865826577),\n",
       " ('gbc_13', 0.0035792258534387794),\n",
       " ('gbc_6', 0.0034737453523762808),\n",
       " ('lr_1', 0.0033900165442831546),\n",
       " ('bnb_16', 0.0033815616540560484),\n",
       " ('lr_11', 0.0032856826405205865),\n",
       " ('lr_17', 0.0032439985174499875),\n",
       " ('svm_18', 0.0031961580002302079),\n",
       " ('fnn_16', 0.0031476262199068273),\n",
       " ('svm_4', 0.0031124034499414406),\n",
       " ('dtc_9', 0.0030912831859837386),\n",
       " ('svm_6', 0.0030497782601192108),\n",
       " ('fnn_1', 0.0029765710884088036),\n",
       " ('fnn_2', 0.0029205451016398004),\n",
       " ('svm_3', 0.0028442801155934725),\n",
       " ('dtc_7', 0.0028278163241321442),\n",
       " ('lr_14', 0.0028250468561053727),\n",
       " ('svm_1', 0.0028136906573557451),\n",
       " ('svm_7', 0.0027682911838421685),\n",
       " ('etc_5', 0.0027147563366224079),\n",
       " ('etc_0', 0.0026193864933287225),\n",
       " ('fnn_14', 0.002565810290259075),\n",
       " ('etc_8', 0.0025333495875346449),\n",
       " ('knn_6', 0.0024577123653300595),\n",
       " ('knn_7', 0.0023352027307947678),\n",
       " ('rfc_19', 0.002228430247313454),\n",
       " ('lr_15', 0.0021814819359044137),\n",
       " ('fnn_0', 0.0019344555589877119),\n",
       " ('bnb_6', 0.0018387857971382227),\n",
       " ('lr_12', 0.0017506119650698389),\n",
       " ('fnn_4', 0.0016022182218219092),\n",
       " ('dtc_15', 0.0015873816538898205),\n",
       " ('etc_7', 0.0015491271079629426),\n",
       " ('gbc_17', 0.0015086175296849188),\n",
       " ('dtc_12', 0.0014755773098489376),\n",
       " ('rfc_14', 0.0014729951307853862),\n",
       " ('gbc_11', 0.0014191023260691259),\n",
       " ('svm_19', 0.0013038516619587929),\n",
       " ('bnb_14', 0.0012597093160579621),\n",
       " ('dtc_14', 0.0012131132161363285),\n",
       " ('lr_16', 0.0010394632218713616),\n",
       " ('bnb_3', 0.00097024550398820025),\n",
       " ('knn_1', 0.00089768638836148151),\n",
       " ('dtc_0', 0.00070739405769206995),\n",
       " ('knn_2', 0.00059935580958501674),\n",
       " ('etc_4', 0.00031111237353794266),\n",
       " ('fnn_17', 4.6957206037292856e-05),\n",
       " ('etc_3', 0.0),\n",
       " ('etc_14', 0.0),\n",
       " ('dtc_1', 0.0),\n",
       " ('dtc_2', 0.0),\n",
       " ('dtc_3', 0.0),\n",
       " ('dtc_5', 0.0),\n",
       " ('dtc_6', 0.0),\n",
       " ('dtc_8', 0.0),\n",
       " ('dtc_11', 0.0),\n",
       " ('dtc_13', 0.0),\n",
       " ('dtc_16', 0.0),\n",
       " ('dtc_17', 0.0),\n",
       " ('dtc_19', 0.0),\n",
       " ('bnb_0', 0.0),\n",
       " ('bnb_1', 0.0),\n",
       " ('bnb_2', 0.0),\n",
       " ('bnb_4', 0.0),\n",
       " ('bnb_5', 0.0),\n",
       " ('bnb_7', 0.0),\n",
       " ('bnb_8', 0.0),\n",
       " ('bnb_9', 0.0),\n",
       " ('bnb_10', 0.0),\n",
       " ('bnb_11', 0.0),\n",
       " ('bnb_12', 0.0),\n",
       " ('bnb_13', 0.0),\n",
       " ('bnb_15', 0.0),\n",
       " ('bnb_17', 0.0),\n",
       " ('bnb_19', 0.0),\n",
       " ('lr_10', 0.0),\n",
       " ('lr_18', 0.0),\n",
       " ('fnn_7', 0.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imps_for_level1preds_w_gbc_mf7_all_trainset_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate auc of each (single) feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc_0: 0.8495\n",
      "gbc_1: 0.8501\n",
      "gbc_2: 0.8493\n",
      "gbc_3: 0.8503\n",
      "gbc_4: 0.8483\n",
      "gbc_5: 0.8506\n",
      "gbc_6: 0.8496\n",
      "gbc_7: 0.8488\n",
      "gbc_8: 0.8503\n",
      "gbc_9: 0.8515\n",
      "gbc_10: 0.8494\n",
      "gbc_11: 0.8500\n",
      "gbc_12: 0.8501\n",
      "gbc_13: 0.8502\n",
      "gbc_14: 0.8492\n",
      "gbc_15: 0.8497\n",
      "gbc_16: 0.8489\n",
      "gbc_17: 0.8508\n",
      "gbc_18: 0.8501\n",
      "gbc_19: 0.8498\n",
      "xgb_0: 0.8544\n",
      "xgb_1: 0.8543\n",
      "xgb_2: 0.8548\n",
      "xgb_3: 0.8558\n",
      "xgb_4: 0.8532\n",
      "xgb_5: 0.8554\n",
      "xgb_6: 0.8549\n",
      "xgb_7: 0.8542\n",
      "xgb_8: 0.8550\n",
      "xgb_9: 0.8558\n",
      "xgb_10: 0.8557\n",
      "xgb_11: 0.8555\n",
      "xgb_12: 0.8551\n",
      "xgb_13: 0.8555\n",
      "xgb_14: 0.8554\n",
      "xgb_15: 0.8544\n",
      "xgb_16: 0.8550\n",
      "xgb_17: 0.8558\n",
      "xgb_18: 0.8545\n",
      "xgb_19: 0.8555\n",
      "etc_0: 0.8508\n",
      "etc_1: 0.8498\n",
      "etc_2: 0.8503\n",
      "etc_3: 0.8513\n",
      "etc_4: 0.8502\n",
      "etc_5: 0.8514\n",
      "etc_6: 0.8503\n",
      "etc_7: 0.8503\n",
      "etc_8: 0.8512\n",
      "etc_9: 0.8517\n",
      "etc_10: 0.8509\n",
      "etc_11: 0.8505\n",
      "etc_12: 0.8494\n",
      "etc_13: 0.8509\n",
      "etc_14: 0.8511\n",
      "etc_15: 0.8513\n",
      "etc_16: 0.8515\n",
      "etc_17: 0.8515\n",
      "etc_18: 0.8513\n",
      "etc_19: 0.8502\n",
      "rfc_0: 0.8528\n",
      "rfc_1: 0.8521\n",
      "rfc_2: 0.8527\n",
      "rfc_3: 0.8530\n",
      "rfc_4: 0.8520\n",
      "rfc_5: 0.8533\n",
      "rfc_6: 0.8527\n",
      "rfc_7: 0.8527\n",
      "rfc_8: 0.8534\n",
      "rfc_9: 0.8533\n",
      "rfc_10: 0.8538\n",
      "rfc_11: 0.8529\n",
      "rfc_12: 0.8513\n",
      "rfc_13: 0.8533\n",
      "rfc_14: 0.8528\n",
      "rfc_15: 0.8531\n",
      "rfc_16: 0.8535\n",
      "rfc_17: 0.8541\n",
      "rfc_18: 0.8533\n",
      "rfc_19: 0.8520\n",
      "dtc_0: 0.8202\n",
      "dtc_1: 0.8254\n",
      "dtc_2: 0.8264\n",
      "dtc_3: 0.8270\n",
      "dtc_4: 0.8240\n",
      "dtc_5: 0.8179\n",
      "dtc_6: 0.8291\n",
      "dtc_7: 0.8286\n",
      "dtc_8: 0.8215\n",
      "dtc_9: 0.8199\n",
      "dtc_10: 0.8239\n",
      "dtc_11: 0.8270\n",
      "dtc_12: 0.8284\n",
      "dtc_13: 0.8235\n",
      "dtc_14: 0.8268\n",
      "dtc_15: 0.8268\n",
      "dtc_16: 0.8182\n",
      "dtc_17: 0.8297\n",
      "dtc_18: 0.8262\n",
      "dtc_19: 0.8246\n",
      "bnb_0: 0.7252\n",
      "bnb_1: 0.7123\n",
      "bnb_2: 0.7234\n",
      "bnb_3: 0.7204\n",
      "bnb_4: 0.7132\n",
      "bnb_5: 0.7136\n",
      "bnb_6: 0.7156\n",
      "bnb_7: 0.7245\n",
      "bnb_8: 0.7225\n",
      "bnb_9: 0.7197\n",
      "bnb_10: 0.7153\n",
      "bnb_11: 0.7137\n",
      "bnb_12: 0.7137\n",
      "bnb_13: 0.7215\n",
      "bnb_14: 0.7134\n",
      "bnb_15: 0.7127\n",
      "bnb_16: 0.7147\n",
      "bnb_17: 0.7224\n",
      "bnb_18: 0.7196\n",
      "bnb_19: 0.7138\n",
      "lr_0: 0.8438\n",
      "lr_1: 0.8442\n",
      "lr_2: 0.8440\n",
      "lr_3: 0.8447\n",
      "lr_4: 0.8428\n",
      "lr_5: 0.8439\n",
      "lr_6: 0.8441\n",
      "lr_7: 0.8435\n",
      "lr_8: 0.8445\n",
      "lr_9: 0.8442\n",
      "lr_10: 0.8441\n",
      "lr_11: 0.8440\n",
      "lr_12: 0.8440\n",
      "lr_13: 0.8443\n",
      "lr_14: 0.8442\n",
      "lr_15: 0.8439\n",
      "lr_16: 0.8440\n",
      "lr_17: 0.8442\n",
      "lr_18: 0.8439\n",
      "lr_19: 0.8440\n",
      "svm_0: 0.8381\n",
      "svm_1: 0.8374\n",
      "svm_2: 0.8375\n",
      "svm_3: 0.8389\n",
      "svm_4: 0.8362\n",
      "svm_5: 0.8382\n",
      "svm_6: 0.8380\n",
      "svm_7: 0.8374\n",
      "svm_8: 0.8374\n",
      "svm_9: 0.8378\n",
      "svm_10: 0.8378\n",
      "svm_11: 0.8373\n",
      "svm_12: 0.8366\n",
      "svm_13: 0.8376\n",
      "svm_14: 0.8377\n",
      "svm_15: 0.8378\n",
      "svm_16: 0.8374\n",
      "svm_17: 0.8378\n",
      "svm_18: 0.8372\n",
      "svm_19: 0.8377\n",
      "knn_0: 0.8382\n",
      "knn_1: 0.8375\n",
      "knn_2: 0.8379\n",
      "knn_3: 0.8392\n",
      "knn_4: 0.8371\n",
      "knn_5: 0.8383\n",
      "knn_6: 0.8392\n",
      "knn_7: 0.8393\n",
      "fnn_0: 0.8409\n",
      "fnn_1: 0.8411\n",
      "fnn_2: 0.8407\n",
      "fnn_3: 0.8419\n",
      "fnn_4: 0.8396\n",
      "fnn_5: 0.8410\n",
      "fnn_6: 0.8409\n",
      "fnn_7: 0.8400\n",
      "fnn_8: 0.8410\n",
      "fnn_9: 0.8408\n",
      "fnn_10: 0.8404\n",
      "fnn_11: 0.8411\n",
      "fnn_12: 0.8406\n",
      "fnn_13: 0.8414\n",
      "fnn_14: 0.8410\n",
      "fnn_15: 0.8411\n",
      "fnn_16: 0.8404\n",
      "fnn_17: 0.8414\n",
      "fnn_18: 0.8401\n",
      "fnn_19: 0.8407\n"
     ]
    }
   ],
   "source": [
    "features = trainFeatures.columns\n",
    "aucs = {}\n",
    "for clf in features:\n",
    "    aucs[clf] = roc_auc_score(trainLabels, trainFeatures[clf])\n",
    "    print \"%s: %.4f\" % (clf, aucs[clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_auc_scores_sorted = sorted(aucs.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/feature_auc_scores_sorted.joblib']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(feature_auc_scores_sorted, './data/feature_auc_scores_sorted.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('xgb_17', 0.85583854994763331)),\n",
       " (2, ('xgb_9', 0.85582707331117824)),\n",
       " (3, ('xgb_3', 0.8557792065622265)),\n",
       " (4, ('xgb_10', 0.85568770309616826)),\n",
       " (5, ('xgb_11', 0.85554351319471234)),\n",
       " (6, ('xgb_19', 0.85552120193955294)),\n",
       " (7, ('xgb_13', 0.85551561501912832)),\n",
       " (8, ('xgb_14', 0.85544431689894163)),\n",
       " (9, ('xgb_5', 0.85543157899357258)),\n",
       " (10, ('xgb_12', 0.85510617389038934)),\n",
       " (11, ('xgb_16', 0.85504473142567072)),\n",
       " (12, ('xgb_8', 0.85503081876441756)),\n",
       " (13, ('xgb_6', 0.85491032660326316)),\n",
       " (14, ('xgb_2', 0.85477536172281787)),\n",
       " (15, ('xgb_18', 0.8544607821317044)),\n",
       " (16, ('xgb_0', 0.85443558179666779)),\n",
       " (17, ('xgb_15', 0.85441539238740716)),\n",
       " (18, ('xgb_1', 0.85433304791925779)),\n",
       " (19, ('xgb_7', 0.85418351925317437)),\n",
       " (20, ('rfc_17', 0.85410663648922192)),\n",
       " (21, ('rfc_10', 0.85377899343054664)),\n",
       " (22, ('rfc_16', 0.85345428498492237)),\n",
       " (23, ('rfc_8', 0.85339112364289282)),\n",
       " (24, ('rfc_18', 0.85334475721201763)),\n",
       " (25, ('rfc_9', 0.85333918167488654)),\n",
       " (26, ('rfc_5', 0.85328389984858222)),\n",
       " (27, ('rfc_13', 0.85326526767386535)),\n",
       " (28, ('xgb_4', 0.85317994078283266)),\n",
       " (29, ('rfc_15', 0.85313490392063218)),\n",
       " (30, ('rfc_3', 0.85304404247232468)),\n",
       " (31, ('rfc_11', 0.85286871015665155)),\n",
       " (32, ('rfc_14', 0.85281087847261483)),\n",
       " (33, ('rfc_0', 0.8527933094975062)),\n",
       " (34, ('rfc_2', 0.8527316849000921)),\n",
       " (35, ('rfc_6', 0.8527275299979834)),\n",
       " (36, ('rfc_7', 0.85269274720652155)),\n",
       " (37, ('rfc_1', 0.85205552637587401)),\n",
       " (38, ('rfc_4', 0.85204546126780667)),\n",
       " (39, ('rfc_19', 0.85203901832371476)),\n",
       " (40, ('etc_9', 0.85169717802145017)),\n",
       " (41, ('etc_17', 0.85150533993027677)),\n",
       " (42, ('etc_16', 0.85148576066554493)),\n",
       " (43, ('gbc_9', 0.8514842967740075)),\n",
       " (44, ('etc_5', 0.85135215267367892)),\n",
       " (45, ('etc_3', 0.85133502537035588)),\n",
       " (46, ('etc_18', 0.85132115824227672)),\n",
       " (47, ('rfc_12', 0.85130585909588163)),\n",
       " (48, ('etc_15', 0.85128186083663315)),\n",
       " (49, ('etc_8', 0.8511510667949076)),\n",
       " (50, ('etc_14', 0.85109290271870197)),\n",
       " (51, ('etc_13', 0.85094284586780256)),\n",
       " (52, ('etc_10', 0.8509020458674238)),\n",
       " (53, ('etc_0', 0.8508274852953347)),\n",
       " (54, ('gbc_17', 0.85075371700046976)),\n",
       " (55, ('gbc_5', 0.8505567791938311)),\n",
       " (56, ('etc_11', 0.85052929537012845)),\n",
       " (57, ('etc_2', 0.85034963967960375)),\n",
       " (58, ('etc_6', 0.85028253061140635)),\n",
       " (59, ('gbc_3', 0.85027581674493025)),\n",
       " (60, ('gbc_8', 0.8502669514359924)),\n",
       " (61, ('etc_7', 0.85026375045387459)),\n",
       " (62, ('etc_4', 0.8502124140770797)),\n",
       " (63, ('etc_19', 0.85019793680447164)),\n",
       " (64, ('gbc_13', 0.85017927730985066)),\n",
       " (65, ('gbc_12', 0.85013444307027353)),\n",
       " (66, ('gbc_18', 0.85006426278950342)),\n",
       " (67, ('gbc_1', 0.85005998722448428)),\n",
       " (68, ('gbc_11', 0.84997367226358023)),\n",
       " (69, ('etc_1', 0.84976788736127329)),\n",
       " (70, ('gbc_19', 0.84976512122096515)),\n",
       " (71, ('gbc_15', 0.8496844546502702)),\n",
       " (72, ('gbc_6', 0.84958221901514885)),\n",
       " (73, ('gbc_0', 0.84946365290724568)),\n",
       " (74, ('etc_12', 0.84944830139770078)),\n",
       " (75, ('gbc_10', 0.84939653928573089)),\n",
       " (76, ('gbc_2', 0.84931106213522467)),\n",
       " (77, ('gbc_14', 0.84917140733787855)),\n",
       " (78, ('gbc_16', 0.84890987161757736)),\n",
       " (79, ('gbc_7', 0.84877777532708121)),\n",
       " (80, ('gbc_4', 0.84834351178864797)),\n",
       " (81, ('lr_3', 0.84470328024990937)),\n",
       " (82, ('lr_8', 0.84448870061508408)),\n",
       " (83, ('lr_13', 0.84426175644691459)),\n",
       " (84, ('lr_9', 0.8442473702406541)),\n",
       " (85, ('lr_14', 0.84420323493529481)),\n",
       " (86, ('lr_1', 0.84418789253238469)),\n",
       " (87, ('lr_17', 0.84415188489854764)),\n",
       " (88, ('lr_10', 0.84411879366449227)),\n",
       " (89, ('lr_6', 0.84406105304680312)),\n",
       " (90, ('lr_11', 0.84403336887713576)),\n",
       " (91, ('lr_2', 0.84401911016376197)),\n",
       " (92, ('lr_19', 0.84401891892443226)),\n",
       " (93, ('lr_16', 0.84396862298065844)),\n",
       " (94, ('lr_12', 0.84396480957735309)),\n",
       " (95, ('lr_5', 0.84388539972225507)),\n",
       " (96, ('lr_18', 0.84388213044037641)),\n",
       " (97, ('lr_15', 0.84385898365147782)),\n",
       " (98, ('lr_0', 0.84381167013058767)),\n",
       " (99, ('lr_7', 0.84350813005746073)),\n",
       " (100, ('lr_4', 0.84284805385022687)),\n",
       " (101, ('fnn_3', 0.84193846951054985)),\n",
       " (102, ('fnn_17', 0.84141294838519687)),\n",
       " (103, ('fnn_13', 0.84137545864655305)),\n",
       " (104, ('fnn_15', 0.84112133117362808)),\n",
       " (105, ('fnn_11', 0.8410717341640721)),\n",
       " (106, ('fnn_1', 0.84105472752365973)),\n",
       " (107, ('fnn_14', 0.84101402086628718)),\n",
       " (108, ('fnn_5', 0.84097547475801127)),\n",
       " (109, ('fnn_8', 0.84096121376797872)),\n",
       " (110, ('fnn_6', 0.84094504949128157)),\n",
       " (111, ('fnn_0', 0.84094436877033329)),\n",
       " (112, ('fnn_9', 0.84084923175700643)),\n",
       " (113, ('fnn_2', 0.84072127670866692)),\n",
       " (114, ('fnn_19', 0.84067866221131238)),\n",
       " (115, ('fnn_12', 0.84059495630126679)),\n",
       " (116, ('fnn_10', 0.84038996367618379)),\n",
       " (117, ('fnn_16', 0.84036345198574181)),\n",
       " (118, ('fnn_18', 0.84009227689254806)),\n",
       " (119, ('fnn_7', 0.84000520608095908)),\n",
       " (120, ('fnn_4', 0.83958678125703035)),\n",
       " (121, ('knn_7', 0.83933833632419497)),\n",
       " (122, ('knn_6', 0.83924779360810409)),\n",
       " (123, ('knn_3', 0.83922683924152375)),\n",
       " (124, ('svm_3', 0.83885652704568525)),\n",
       " (125, ('knn_5', 0.83833775849000625)),\n",
       " (126, ('knn_0', 0.83820316698158615)),\n",
       " (127, ('svm_5', 0.8381865929063248)),\n",
       " (128, ('svm_0', 0.838112127953901)),\n",
       " (129, ('svm_6', 0.83798496745944417)),\n",
       " (130, ('knn_2', 0.83790750187086704)),\n",
       " (131, ('svm_15', 0.83778179388465435)),\n",
       " (132, ('svm_10', 0.83777754791619796)),\n",
       " (133, ('svm_9', 0.83777243909409815)),\n",
       " (134, ('svm_17', 0.8377619732941014)),\n",
       " (135, ('svm_14', 0.83772452225865524)),\n",
       " (136, ('svm_19', 0.83772197695424)),\n",
       " (137, ('svm_13', 0.83757698339226661)),\n",
       " (138, ('knn_1', 0.83749315454265161)),\n",
       " (139, ('svm_2', 0.83747486842005581)),\n",
       " (140, ('svm_16', 0.83737683322021672)),\n",
       " (141, ('svm_1', 0.83737124629979209)),\n",
       " (142, ('svm_7', 0.83737072949826963)),\n",
       " (143, ('svm_8', 0.83736017946190133)),\n",
       " (144, ('svm_11', 0.83728560978317756)),\n",
       " (145, ('svm_18', 0.83715464954536767)),\n",
       " (146, ('knn_4', 0.83705320618747026)),\n",
       " (147, ('svm_12', 0.8365523458290447)),\n",
       " (148, ('svm_4', 0.83624962307638728)),\n",
       " (149, ('dtc_17', 0.82973480942290456)),\n",
       " (150, ('dtc_6', 0.82913502824440977)),\n",
       " (151, ('dtc_7', 0.82863099877708812)),\n",
       " (152, ('dtc_12', 0.82836426316833967)),\n",
       " (153, ('dtc_3', 0.82695589478296194)),\n",
       " (154, ('dtc_11', 0.8269551343789594)),\n",
       " (155, ('dtc_14', 0.82677175635147715)),\n",
       " (156, ('dtc_15', 0.82676704822130653)),\n",
       " (157, ('dtc_2', 0.82643392069184773)),\n",
       " (158, ('dtc_18', 0.82623836709369258)),\n",
       " (159, ('dtc_1', 0.82538440835578186)),\n",
       " (160, ('dtc_19', 0.82455867335564781)),\n",
       " (161, ('dtc_4', 0.82398846825019134)),\n",
       " (162, ('dtc_10', 0.82393158593282823)),\n",
       " (163, ('dtc_13', 0.82345844617060915)),\n",
       " (164, ('dtc_8', 0.82152758689259464)),\n",
       " (165, ('dtc_0', 0.82016326046957022)),\n",
       " (166, ('dtc_9', 0.81986412573100775)),\n",
       " (167, ('dtc_16', 0.81815911099501559)),\n",
       " (168, ('dtc_5', 0.81792506820505173)),\n",
       " (169, ('bnb_0', 0.72517064649675778)),\n",
       " (170, ('bnb_7', 0.72446974752255822)),\n",
       " (171, ('bnb_2', 0.72341176601616641)),\n",
       " (172, ('bnb_8', 0.72247464321297816)),\n",
       " (173, ('bnb_17', 0.72237748452673467)),\n",
       " (174, ('bnb_13', 0.72154348070223939)),\n",
       " (175, ('bnb_3', 0.72042397477141618)),\n",
       " (176, ('bnb_9', 0.71965122444896856)),\n",
       " (177, ('bnb_18', 0.71958775120469864)),\n",
       " (178, ('bnb_6', 0.71563347964295576)),\n",
       " (179, ('bnb_10', 0.71527180509018629)),\n",
       " (180, ('bnb_16', 0.71465661776233813)),\n",
       " (181, ('bnb_19', 0.71377585592167303)),\n",
       " (182, ('bnb_12', 0.71372533231203017)),\n",
       " (183, ('bnb_11', 0.71369081133631773)),\n",
       " (184, ('bnb_5', 0.71364691280346237)),\n",
       " (185, ('bnb_14', 0.71342155091308213)),\n",
       " (186, ('bnb_4', 0.71316765338268484)),\n",
       " (187, ('bnb_15', 0.71270432374275994)),\n",
       " (188, ('bnb_1', 0.71231682960378995))]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(range(1,189), feature_auc_scores_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate with best auc estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to calculate weighted averages\n",
    "def wavg(row):\n",
    "  avg = 0.\n",
    "  for feat, score in feats:\n",
    "    avg += (row[feat] * score) / float(sum([score for feat, score in feats]))\n",
    "  return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function for minmax() predictions\n",
    "# minmax(), firstly makes a hard vote on all predictors, decides a class (ie. 0 or 1), and then, \n",
    "# sets the predict_proba score with max() if class is 1 and min() if class is zero.\n",
    "def minmax(row):\n",
    "    min_pred = 2\n",
    "    max_pred = -1\n",
    "    n_preds_1 = 0\n",
    "    for feat, score in feats:\n",
    "        if row[feat] > .5:\n",
    "            n_preds_1 += 1\n",
    "        if row[feat] < min_pred:\n",
    "            min_pred = row[feat]\n",
    "        if row[feat] > max_pred:\n",
    "            max_pred = row[feat]\n",
    "    if n_preds_1 > n_preds_total / 2.:\n",
    "        return max_pred\n",
    "    else:\n",
    "        return min_pred    \n",
    "    # runs too slowly:\n",
    "    #n_preds_1 = len(row[features][row[features] > 0.5])\n",
    "    #if n_preds_1 > n_preds_total / 2.:\n",
    "    #    return row[features].max()\n",
    "    #else:\n",
    "    #    return row[features].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 validation auc: 0.8521\n",
      "  1 validation auc: 0.8508\n",
      "  2 validation auc: 0.8549\n",
      "  3 validation auc: 0.8511\n",
      "  4 validation auc: 0.8553\n",
      "  5 validation auc: 0.8539\n",
      "  6 validation auc: 0.8522\n",
      "  7 validation auc: 0.8525\n",
      "  8 validation auc: 0.8515\n",
      "  9 validation auc: 0.8490\n",
      " 10 validation auc: 0.8565\n",
      " 11 validation auc: 0.8537\n",
      " 12 validation auc: 0.8538\n",
      " 13 validation auc: 0.8520\n",
      " 14 validation auc: 0.8504\n",
      " 15 validation auc: 0.8530\n",
      " 16 validation auc: 0.8536\n",
      " 17 validation auc: 0.8548\n",
      " 18 validation auc: 0.8590\n",
      " 19 validation auc: 0.8543\n",
      " 20 validation auc: 0.8519\n",
      " 21 validation auc: 0.8538\n",
      " 22 validation auc: 0.8534\n",
      " 23 validation auc: 0.8578\n",
      " 24 validation auc: 0.8498\n",
      " 25 validation auc: 0.8535\n",
      " 26 validation auc: 0.8514\n",
      " 27 validation auc: 0.8536\n",
      " 28 validation auc: 0.8594\n",
      " 29 validation auc: 0.8548\n",
      " 30 validation auc: 0.8546\n",
      " 31 validation auc: 0.8608\n",
      " 32 validation auc: 0.8512\n",
      " 33 validation auc: 0.8508\n",
      " 34 validation auc: 0.8577\n",
      " 35 validation auc: 0.8538\n",
      " 36 validation auc: 0.8560\n",
      " 37 validation auc: 0.8549\n",
      " 38 validation auc: 0.8543\n",
      " 39 validation auc: 0.8531\n",
      " 40 validation auc: 0.8548\n",
      " 41 validation auc: 0.8509\n",
      " 42 validation auc: 0.8523\n",
      " 43 validation auc: 0.8512\n",
      " 44 validation auc: 0.8549\n",
      " 45 validation auc: 0.8566\n",
      " 46 validation auc: 0.8567\n",
      " 47 validation auc: 0.8504\n",
      " 48 validation auc: 0.8540\n",
      " 49 validation auc: 0.8566\n",
      " 50 validation auc: 0.8550\n",
      " 51 validation auc: 0.8519\n",
      " 52 validation auc: 0.8509\n",
      " 53 validation auc: 0.8527\n",
      " 54 validation auc: 0.8626\n",
      " 55 validation auc: 0.8565\n",
      " 56 validation auc: 0.8548\n",
      " 57 validation auc: 0.8555\n",
      " 58 validation auc: 0.8562\n",
      " 59 validation auc: 0.8501\n",
      " 60 validation auc: 0.8478\n",
      " 61 validation auc: 0.8546\n",
      " 62 validation auc: 0.8460\n",
      " 63 validation auc: 0.8533\n",
      " 64 validation auc: 0.8516\n",
      " 65 validation auc: 0.8536\n",
      " 66 validation auc: 0.8537\n",
      " 67 validation auc: 0.8569\n",
      " 68 validation auc: 0.8586\n",
      " 69 validation auc: 0.8527\n",
      " 70 validation auc: 0.8478\n",
      " 71 validation auc: 0.8562\n",
      " 72 validation auc: 0.8475\n",
      " 73 validation auc: 0.8554\n",
      " 74 validation auc: 0.8625\n",
      " 75 validation auc: 0.8559\n",
      " 76 validation auc: 0.8589\n",
      " 77 validation auc: 0.8523\n",
      " 78 validation auc: 0.8602\n",
      " 79 validation auc: 0.8557\n",
      " 80 validation auc: 0.8602\n",
      " 81 validation auc: 0.8549\n",
      " 82 validation auc: 0.8552\n",
      " 83 validation auc: 0.8561\n",
      " 84 validation auc: 0.8558\n",
      " 85 validation auc: 0.8503\n",
      " 86 validation auc: 0.8498\n",
      " 87 validation auc: 0.8463\n",
      " 88 validation auc: 0.8494\n",
      " 89 validation auc: 0.8527\n",
      " 90 validation auc: 0.8489\n",
      " 91 validation auc: 0.8587\n",
      " 92 validation auc: 0.8548\n",
      " 93 validation auc: 0.8469\n",
      " 94 validation auc: 0.8469\n",
      " 95 validation auc: 0.8562\n",
      " 96 validation auc: 0.8559\n",
      " 97 validation auc: 0.8526\n",
      " 98 validation auc: 0.8495\n",
      " 99 validation auc: 0.8525\n",
      "-----------------------\n",
      "Best AUC Estimators Voting Classifier with features: [0, 19, 39, 53, 80], weights: imp_score, n_folds: 100, pred_func: wavg\n",
      "Mean: 0.8537\n",
      "Std: 0.0034\n",
      "Total Time (mins): 3.3\n"
     ]
    }
   ],
   "source": [
    "# cross validated performance\n",
    "n_folds = 100\n",
    "weighted = \"imp_score\" # None or \"imp_score\"\n",
    "pred_func = wavg # wavg or minmax\n",
    "val_scores = []\n",
    "r_feats = [1,20,40,54,81] # must be list of 1-based indexes of required features\n",
    "\n",
    "n_feats = [ x-1 for x in r_feats ] # convert to 0-based index values\n",
    "feats = []\n",
    "for ix in n_feats:\n",
    "    if weighted is None:\n",
    "        feats.append( (feature_auc_scores_sorted[ix][0], 1.) )\n",
    "    elif weighted == \"imp_score\":\n",
    "        feats.append( (feature_auc_scores_sorted[ix][0], feature_auc_scores_sorted[ix][1]) )\n",
    "features = [ feat for feat, score in feats ]\n",
    "n_preds_total = len(feats)\n",
    "start = time.time()\n",
    "for i in range(n_folds):\n",
    "    X_val, y_val = getBalancedTrainAndValidationSets(val_only=True)\n",
    "\n",
    "    preds_val = X_val.apply(pred_func, axis=1)\n",
    "    val_score = roc_auc_score(y_val, preds_val)\n",
    "\n",
    "    print \"%3d validation auc: %.4f\" % (i, val_score)\n",
    "    val_scores.append(val_score)\n",
    "\n",
    "print \"-----------------------\"\n",
    "print \"Best AUC Estimators Voting Classifier with features: %s, weights: %s, n_folds: %d, pred_func: %s\" % (\n",
    "        str(n_feats), str(weighted), n_folds, pred_func.__name__)\n",
    "print \"Mean: %.4f\" % np.mean(val_scores)\n",
    "print \"Std: %.4f\" % np.std(val_scores)\n",
    "print \"Total Time (mins): %.1f\" % ((time.time()-start)/60.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
