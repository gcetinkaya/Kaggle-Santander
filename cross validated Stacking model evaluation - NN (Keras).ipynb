{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "#from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2, l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDataFrame = pd.read_csv('./data/trainLevel1Preds.csv')\n",
    "trainLabels = trainDataFrame['TARGET']\n",
    "trainFeatures = trainDataFrame.drop(['TARGET'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print trainDataFrame.shape\n",
    "print trainLabels.shape\n",
    "print trainFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array_equal(trainLabels.index, trainFeatures.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
    "    position and zeroes elsewhere.  This is used to convert a digit\n",
    "    (0...9) into a corresponding desired output from the neural\n",
    "    network.\"\"\"\n",
    "    e = np.zeros((2, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataTarget0 = trainDataFrame[trainDataFrame.TARGET == 0]\n",
    "dataTarget1 = trainDataFrame[trainDataFrame.TARGET == 1]\n",
    "np.random.seed(1)\n",
    "\n",
    "def getBalancedTrainAndValidationSets(scale=False):\n",
    "    # shuffle\n",
    "    dt0 = dataTarget0.reindex(np.random.permutation(dataTarget0.index))\n",
    "    dt1 = dataTarget1.reindex(np.random.permutation(dataTarget1.index))\n",
    "    trn0 = dt0[0:3000]\n",
    "    trn1 = dt1[0:1500]\n",
    "    trn = pd.concat([trn0, trn1])\n",
    "    y_train = trn['TARGET']\n",
    "    X_train = trn.drop(['TARGET'], axis=1)\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_train = pd.DataFrame(X_train)\n",
    "    val0 = dt0[3000:6000]\n",
    "    val1 = dt1[1500:]\n",
    "    val = pd.concat([val0, val1])\n",
    "    y_val = val['TARGET']\n",
    "    X_val = val.drop(['TARGET'], axis=1)\n",
    "    if scale:\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # CREATE THE MODEL\n",
    "    # set model_id and checkpointer object\n",
    "    model_id = \"./models/keras/last_keras_model_checkpoint\"\n",
    "    checkpointer = None\n",
    "    # to monitor validation accuracy:\n",
    "    # checkpointer = ModelCheckpoint(filepath=model_id+\".hdf5\", monitor='val_loss', verbose=1, save_best_only=False)\n",
    "    # to monitor validation loss:\n",
    "    # checkpointer = ModelCheckpoint(filepath=model_id+\".hdf5\", verbose=1, save_best_only=False)\n",
    "    # create Sequential model\n",
    "    model = Sequential()\n",
    "    # 1. hidden layer\n",
    "    model.add(Dense(output_dim=2, input_dim=188))#, W_regularizer=l1(0.01))) #W_regularizer=l2(0.1), \n",
    "    model.add(Activation('sigmoid'))\n",
    "    # 2. hidden\n",
    "    #model.add(Dense(output_dim=100, W_regularizer=l2(0.01))) #W_regularizer=l2(0.1), \n",
    "    #model.add(Activation('sigmoid'))\n",
    "    #model.add(Dense(output_dim=100, W_regularizer=l2(0.01))) #W_regularizer=l2(0.1), \n",
    "    #model.add(Activation('sigmoid'))\n",
    "    #model.add(Dense(output_dim=100, W_regularizer=l2(0.01))) #W_regularizer=l2(0.1), \n",
    "    #model.add(Activation('sigmoid'))\n",
    "    # output layer\n",
    "    model.add(Dense(output_dim=2))#, W_regularizer=l1(0.01))) #, W_regularizer=l2(0.1)\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    # SGD(lr=0.005, momentum=0.1, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model, checkpointer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CROSS VALIDATE\n",
    "n_folds = 100\n",
    "start = time.time()\n",
    "trn_scores = []\n",
    "val_scores = []\n",
    "for i in range(n_folds):\n",
    "    #print \"Running Fold\", i+1, \"/\", n_folds\n",
    "    model = None # Clearing the NN.\n",
    "    model, checkpointer = get_model()\n",
    "    X_train, y_train, X_valid, y_valid = getBalancedTrainAndValidationSets()\n",
    "    y_train_vect = np.array([vectorized_result(x) for x in y_train])\n",
    "    y_train_vect = np.reshape(y_train_vect, (y_train_vect.shape[0], 2))\n",
    "    y_valid_vect = np.array([vectorized_result(x) for x in y_valid])\n",
    "    y_valid_vect = np.reshape(y_valid_vect, (y_valid_vect.shape[0], 2))\n",
    "    model.fit(X_train.as_matrix(), y_train_vect, verbose=0, batch_size=10, nb_epoch=400, validation_data=(X_valid.as_matrix(), y_valid_vect)) #, callbacks=[checkpointer]\n",
    "    trn_score = roc_auc_score(y_train, model.predict_proba(X_train.as_matrix())[:,1])\n",
    "    val_score = roc_auc_score(y_valid, model.predict_proba(X_valid.as_matrix())[:,1])\n",
    "    #print \"train auc: %.4f\" % trn_score\n",
    "    #print \"validation auc: %.4f\" % val_score\n",
    "    print \"(%d/%d) Train (AUC): %.4f Validation (AUC): %.4f\" % (i, n_folds, trn_score, val_score)\n",
    "    trn_scores.append(trn_score)\n",
    "    val_scores.append(val_score)\n",
    "    \n",
    "stop = time.time()\n",
    "print \"-----------------------\"\n",
    "print \"Results for %d fold cross validation:\" % (n_folds)\n",
    "print \"Train Mean: %.4f\" % np.mean(trn_scores)\n",
    "print \"Train std: %.4f\" % np.std(trn_scores)\n",
    "print \"Validation Mean: %.4f\" % np.mean(val_scores)\n",
    "print \"Validation std: %.4f\" % np.std(val_scores)\n",
    "print \"Total time (mins): %.1f (%.1f/fold)\" % ((stop-start)/60., (stop-start)/(60.*n_folds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
