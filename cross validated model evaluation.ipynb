{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainTransformedDF = pd.read_csv('./data/trainTransformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 3921)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTransformedDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73012\n",
       "1     3008\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTransformedDF.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataTarget0 = trainTransformedDF[trainTransformedDF.TARGET == 0]\n",
    "dataTarget1 = trainTransformedDF[trainTransformedDF.TARGET == 1]\n",
    "\n",
    "def getBalancedTrainAndValidationSets():\n",
    "    np.random.seed()\n",
    "    # shuffle\n",
    "    dataTarget0.reindex(np.random.permutation(dataTarget0.index))\n",
    "    dataTarget1.reindex(np.random.permutation(dataTarget1.index))\n",
    "\n",
    "    trn0 = dataTarget0[0:1500]\n",
    "    trn1 = dataTarget1[0:1500]\n",
    "    trn = pd.concat([trn0, trn1])\n",
    "    y_train = trn['TARGET']\n",
    "    X_train = trn.drop(['TARGET'], axis=1)\n",
    "    \n",
    "    val0 = dataTarget0[1500:3000]\n",
    "    val1 = dataTarget1[1500:]\n",
    "    val = pd.concat([val0, val1])\n",
    "    y_val = val['TARGET']\n",
    "    X_val = val.drop(['TARGET'], axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.8689\n",
      "validation auc: 0.8409\n",
      "train auc: 0.8701\n",
      "validation auc: 0.8407\n",
      "train auc: 0.8691\n",
      "validation auc: 0.8400\n",
      "train auc: 0.8695\n",
      "validation auc: 0.8393\n",
      "train auc: 0.8682\n",
      "validation auc: 0.8392\n",
      "-----------------------\n",
      "Train Mean: 0.8691\n",
      "Validation Mean: 0.8400\n",
      "Total Time (mins): 5.6\n"
     ]
    }
   ],
   "source": [
    "# cross validated performance\n",
    "n_folds = 5\n",
    "clf = GradientBoostingClassifier(max_features=12)\n",
    "trn_scores = []\n",
    "val_scores = []\n",
    "start = time.time()\n",
    "for i in range(n_folds):\n",
    "    X_train, y_train, X_val, y_val = getBalancedTrainAndValidationSets()\n",
    "    clf.fit(X_train, y_train)\n",
    "    # evaluate w .predict_proba() !!!! :\n",
    "    trn_score = roc_auc_score(y_train, clf.predict_proba(X_train)[:,1])\n",
    "    val_score = roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])\n",
    "    # evaluate w .predict():\n",
    "    # trn_score = roc_auc_score(y_train, clf.predict(X_train))\n",
    "    # val_score = roc_auc_score(y_val, clf.predict(X_val))\n",
    "    print \"train auc: %.4f\" % trn_score\n",
    "    print \"validation auc: %.4f\" % val_score\n",
    "    trn_scores.append(trn_score)\n",
    "    val_scores.append(val_score)\n",
    "\n",
    "print \"-----------------------\"\n",
    "print \"Train Mean: %.4f\" % np.mean(trn_scores)\n",
    "print \"Validation Mean: %.4f\" % np.mean(val_scores)\n",
    "print \"Total Time (mins): %.1f\" % ((time.time()-start)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3920)\n",
      "(3000,)\n",
      "(3008, 3920)\n",
      "(3008,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_val.shape\n",
    "print y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1054,  446],\n",
       "       [ 419, 1089]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, clf.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY WITH ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDataFrame = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# remove constant columns\n",
    "colsToRemove1 = []\n",
    "for col in trainDataFrame.columns:\n",
    "    if trainDataFrame[col].std() == 0:\n",
    "        colsToRemove1.append(col)\n",
    "\n",
    "trainDataFrame.drop(colsToRemove1, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicate columns\n",
    "colsToRemove2 = []\n",
    "columns = trainDataFrame.columns\n",
    "for i in range(len(columns)-1):\n",
    "    v = trainDataFrame[columns[i]].values\n",
    "    for j in range(i+1,len(columns)):\n",
    "        if np.array_equal(v,trainDataFrame[columns[j]].values):\n",
    "            colsToRemove2.append(columns[j])\n",
    "\n",
    "trainDataFrame.drop(colsToRemove2, axis=1, inplace=True)\n",
    "\n",
    "#trainLabels = trainDataFrame['TARGET']\n",
    "#trainFeatures = trainDataFrame.drop(['ID','TARGET'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainTransformedDF = trainDataFrame.drop(['ID'], axis=1)\n",
    "dataTarget0 = trainTransformedDF[trainTransformedDF.TARGET == 0]\n",
    "dataTarget1 = trainTransformedDF[trainTransformedDF.TARGET == 1]\n",
    "\n",
    "def getBalancedTrainAndValidationSets():\n",
    "    # shuffle\n",
    "    dataTarget0.reindex(np.random.permutation(dataTarget0.index))\n",
    "    dataTarget1.reindex(np.random.permutation(dataTarget1.index))\n",
    "\n",
    "    trn0 = dataTarget0[0:1500]\n",
    "    trn1 = dataTarget1[0:1500]\n",
    "    trn = pd.concat([trn0, trn1])\n",
    "    y_train = trn['TARGET']\n",
    "    X_train = trn.drop(['TARGET'], axis=1)\n",
    "    \n",
    "    val0 = dataTarget0[1500:3000]\n",
    "    val1 = dataTarget1[1500:]\n",
    "    val = pd.concat([val0, val1])\n",
    "    y_val = val['TARGET']\n",
    "    X_val = val.drop(['TARGET'], axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY WITH ORIGINAL BEST 5 FEATURES \n",
    "### from https://www.kaggle.com/selfishgene/santander-customer-satisfaction/advanced-feature-exploration/comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainTransformedDF = trainDataFrame.drop(['ID'], axis=1)\n",
    "trainTransformedDF = trainTransformedDF[['saldo_var30', 'var15', 'saldo_var5', 'ind_var30', 'var38', 'TARGET']]\n",
    "\n",
    "dataTarget0 = trainTransformedDF[trainTransformedDF.TARGET == 0]\n",
    "dataTarget1 = trainTransformedDF[trainTransformedDF.TARGET == 1]\n",
    "\n",
    "def getBalancedTrainAndValidationSets():\n",
    "    # shuffle\n",
    "    dataTarget0.reindex(np.random.permutation(dataTarget0.index))\n",
    "    dataTarget1.reindex(np.random.permutation(dataTarget1.index))\n",
    "\n",
    "    trn0 = dataTarget0[0:1500]\n",
    "    trn1 = dataTarget1[0:1500]\n",
    "    trn = pd.concat([trn0, trn1])\n",
    "    y_train = trn['TARGET']\n",
    "    X_train = trn.drop(['TARGET'], axis=1)\n",
    "    \n",
    "    val0 = dataTarget0[1500:3000]\n",
    "    val1 = dataTarget1[1500:]\n",
    "    val = pd.concat([val0, val1])\n",
    "    y_val = val['TARGET']\n",
    "    X_val = val.drop(['TARGET'], axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTransformedDF.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
