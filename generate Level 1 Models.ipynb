{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level1Clfs = [\n",
    "    {\"model_id\": \"gbc_mf10\", \"clf\": GradientBoostingClassifier(max_features=10)},\n",
    "    {\"model_id\": \"xgb_lr0.005_ne125\", \"clf\": xgboost.XGBClassifier(learning_rate=0.05, n_estimators=125)},\n",
    "    {\"model_id\": \"etc_ne100_md6_mf30\", \"clf\": ExtraTreesClassifier(n_estimators=100, max_depth=6, max_features=30)},\n",
    "    {\"model_id\": \"rfc_ne125_md6\", \"clf\": RandomForestClassifier(n_estimators=125, max_depth=6)},\n",
    "    {\"model_id\": \"dtc_md5_mf75\", \"clf\": DecisionTreeClassifier(max_depth=5, max_features=75)},\n",
    "    {\"model_id\": \"bnb_a0.001\", \"clf\": BernoulliNB(alpha=0.001)},\n",
    "    {\"model_id\": \"lr_c0.001\", \"clf\": LogisticRegression(C=0.001)},\n",
    "    {\"model_id\": \"svm_c0.25_proba_true\", \"clf\": SVC(C=0.25, probability=True)},\n",
    "    {\"model_id\": \"knn_nn75\", \"clf\": KNeighborsClassifier(n_neighbors=75)}, # only 8 models (folds: 0-7) trained for this algo. it takes ~45 mins to train a model on full training set!!!    \n",
    "    {\"model_id\": \"fnn_keras_h100sig_o2softm_regl20.01_bs10_ep100_sgd\", \"clf\": \"Keras [3920, 100 sigmoid (l2(0.01)), 2 softmax (l2(0.01))], batch:10, epochs:100, optimizer: sgd, regularizers: (l2, l2), best_model_metric: None (Last Model of iteration)\"} \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 3921)\n"
     ]
    }
   ],
   "source": [
    "trainTransformedDF = pd.read_csv('./data/trainTransformed.csv') # from schema: ./models/features/merged_schema_best_3920_features.joblib\n",
    "print trainTransformedDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainLabels = trainTransformedDF['TARGET']\n",
    "trainFeatures = trainTransformedDF.drop(['TARGET'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_size = 3650\n",
    "\n",
    "dataTarget0 = trainTransformedDF[trainTransformedDF.TARGET == 0]\n",
    "dataTarget1 = trainTransformedDF[trainTransformedDF.TARGET == 1]\n",
    "\n",
    "def getBalancedTrainSetFold(fold):\n",
    "\n",
    "    if fold == 19:\n",
    "        trn0 = dataTarget0[fold*fold_size:]\n",
    "    else:\n",
    "        trn0 = dataTarget0[fold*fold_size:(fold+1)*fold_size]\n",
    "    #trn1 = dataTarget1[0:1500]\n",
    "    trn = pd.concat([trn0, dataTarget1])\n",
    "    y_train = trn['TARGET']\n",
    "    X_train = trn.drop(['TARGET'], axis=1)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in level1Clfs:\n",
    "    model_id = m[\"model_id\"]\n",
    "    print \"Processing model_id: %s\" % model_id\n",
    "    for fold in range(20): # 20 folds: one model for each fold\n",
    "        start = time.time()\n",
    "        clf = m[\"clf\"]\n",
    "        X, y = getBalancedTrainSetFold(fold)\n",
    "        clf.fit(X, y)\n",
    "        # save the model\n",
    "        joblib.dump(clf, \"./models/level1/%s_%d_of_19.joblib\" % (model_id, fold))\n",
    "        preds = clf.predict_proba(trainFeatures)[:,1]\n",
    "        joblib.dump(preds, \"./data/level1_trn_preds/%s_%d_of_19.joblib\" % (model_id, fold))\n",
    "        print \"Finished processing fold %d of 20 at %.1f mins.\" % (fold+1, (time.time()-start)/60.)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
    "    position and zeroes elsewhere.  This is used to convert a digit\n",
    "    (0...9) into a corresponding desired output from the neural\n",
    "    network.\"\"\"\n",
    "    e = np.zeros((2, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and save model architecture\n",
    "model = Sequential()\n",
    "# 1. hidden layer\n",
    "model.add(Dense(output_dim=100, input_dim=3920, W_regularizer=l2(0.01))) #W_regularizer=l2(0.1), \n",
    "model.add(Activation('sigmoid'))\n",
    "# output layer\n",
    "model.add(Dense(output_dim=2, W_regularizer=l2(0.01))) #, W_regularizer=l2(0.1)\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "joblib.dump(model.to_json(), \"./models/level1/%s.joblib\" % (model_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model_id: fnn_keras_h100sig_o2softm_regl20.01_bs10_ep100_sgd\n",
      "76020/76020 [==============================] - 19s    \n",
      "Finished processing fold 16 of 20 at 6.0 mins.\n",
      "76020/76020 [==============================] - 15s    \n",
      "Finished processing fold 17 of 20 at 5.9 mins.\n",
      "76020/76020 [==============================] - 13s    \n",
      "Finished processing fold 18 of 20 at 5.9 mins.\n",
      "76020/76020 [==============================] - 14s    \n",
      "Finished processing fold 19 of 20 at 5.8 mins.\n",
      "76020/76020 [==============================] - 14s    \n",
      "Finished processing fold 20 of 20 at 5.9 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:489: UserWarning: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 1 is not part of the computational graph needed to compute the outputs: keras_learning_phase.\n",
      "To make this warning into an error, you can pass the parameter on_unused_input='raise' to theano.function. To disable it completely, use on_unused_input='ignore'.\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_id = \"fnn_keras_h100sig_o2softm_regl20.01_bs10_ep100_sgd\"\n",
    "#checkpointer = ModelCheckpoint(filepath=model_id+\".hdf5\", verbose=0, save_best_only=True)\n",
    "print \"Processing model_id: %s\" % model_id\n",
    "\n",
    "for fold in range(20): # 20 folds: one model for each fold\n",
    "    start = time.time()\n",
    "    X, y = getBalancedTrainSetFold(fold)\n",
    "    y_vect = np.array([vectorized_result(x) for x in y])\n",
    "    y_vect = np.reshape(y_vect, (y_vect.shape[0], 2))\n",
    "    clf = None\n",
    "    model_json = joblib.load(\"./models/level1/%s.joblib\" % (model_id))\n",
    "    clf = model_from_json(model_json)\n",
    "\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    clf.fit(X.as_matrix(), y_vect, verbose=0, batch_size=10, \n",
    "                 nb_epoch=100)\n",
    "    \n",
    "    # save the model (weights)\n",
    "    clf.save_weights(\"./models/level1/%s_%d_of_19.HDF5\" % (model_id, fold))\n",
    "    preds = clf.predict_proba(trainFeatures.as_matrix())[:,1]\n",
    "    # save keras level1 preds for train set:\n",
    "    joblib.dump(preds, \"./data/level1_trn_preds/%s_%d_of_19.joblib\" % (model_id, fold))\n",
    "    print \"Finished processing fold %d of 20 at %.1f mins.\" % (fold+1, (time.time()-start)/60.)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test saved model and preds (non-keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_clf = joblib.load('./models/level1/gbc_mf10_0_of_20.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_clf_preds = joblib.load('./data/level1_trn_preds/gbc_mf10_0_of_20.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(test_clf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLabels = trainTransformedDF['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(trainLabels, test_clf_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test saved model and preds (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = joblib.load(\"./models/level1/%s.joblib\" % (model_id))\n",
    "test_clf = model_from_json(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_clf.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_clf.load_weights(\"./models/level1/%s_0_of_19.HDF5\" % (model_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_clf_preds = test_clf.predict_proba(trainFeatures.as_matrix())[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(trainLabels, test_clf_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
